{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn opdrachten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: data inladen en exploratie\n",
    "### Opdracht 1a: Data inladen vanuit scikitlearn.dataset module\n",
    "Laad de iris dataset van de module ``sklearn.datasets`` met behulp van de functie ``load_iris``.\n",
    "De functie returnt een object en heeflt dezelfde attributen als de digits dataset.\n",
    "\n",
    "**Wat is het aantal instanties, features (ookwel attributen) en unieke labels (ookwel target of klassen) in deze dataset? Gebruik een scatterplot om de dataset te visualiseren. Je kunt zelf kiezen welke features je tegen elkaar uitzet in de scatterplot.**\n",
    "\n",
    "*Tip: Je kunt het attribuut ``DESCR`` bekijken om meer te weten te komen over de dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antwoord bij opdracht 1a:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 1b: data inladen vanuit een csv-bestand\n",
    "Normaal gesproken staat je data niet kant en klaar in de scikit library, je zult in de praktijk meemaken dat je een csv-bestand moet inlezen en in de juiste format moet gieten. Probeer nu het csv bestand 'iris.csv' dat op de DLO staat als pandas dataframe in te laden en gebruik dit voor de volgende opdracht. \n",
    "\n",
    "Let op: de labels (de kolom 'class') moet worden verwijderd uit de dataset voordat je het model gaat trainen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antwoord bij opdracht 1b:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Supervised learning\n",
    "### Opdracht 2a: Data splitten\n",
    "We gaan proberen om een classificatie uit te voeren op basis van de ingeladen iris dataset (je mag zelf kiezen of je de dataset bij 1a of 1b gebruikt). De eerste stap is om de dataset op te splitsen in training and testset via train_test_split. \n",
    "\n",
    "**Hoeveel instanties zitten er in de training en tetssets? Komt dit overeen met de verhouding die in de documentatie staat?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antwoord bij opdracht 2a:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 2b: Initialiseren, trainen en evalueren van verschillende modellen\n",
    "Train en evalueer vervolgens de sklearn.neighbors.KNeighborsClassifier, the RandomForestClassifier and sklearn.linear_model.LogisticRegression op de iris dataset.\n",
    "\n",
    "Kijk vervolgens kritisch naar het resultaat en probeer wat vragen te beantwoorden: Hoe performt deze op de training set vs de test set? Welke is het op de training set, welke is het best op de test set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antwoord bij opdracht 2b:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 2c: Evaluatie van de modellen (uitgebreide evaluatie mbv de classification_report module)\n",
    "Maak nu een uitgebreidere evaluatie aan de hand van ``sklearn.metrics.classification_report``. Wat zeggen de resultaten over de classificatie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antwoord bij opdracht 2c:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 2d: Extra opdracht:\n",
    "Wat meer uitdaging: \n",
    "Constueer twee binaire classificatiedataset van 1000 insanties met ieder 3 attributen (bijvoorbeeld met behulp van np.random). De eerste dataset moet een classificatie nauwkeurigheid hebben van '1', de ander moet een nauwkeurigheid van '0.5' hebben. \n",
    "\n",
    "waarop sklearn.linear_model.LogisticRegression een nauwkeurigheid van 1 bereikt? Kun je een binair classificatiedataset construeren waarop het een nauwkeurigheid van 0,5 behaalt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antwoord bij opdracht 2d:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
